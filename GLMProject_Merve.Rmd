---
output:
  html_document: default
  pdf_document: default
---

# Project Documentation: Generalized Linear Models for Meteorological Predictions

---
title: "GLM CM Project"
author: "Merve Telci"
date: "2024-06-30"
output:
  pdf_document: default
  html_document: default
---

## 1. Introduction

This project aims to build and validate predictive models using generalized linear models (GLMs) based on a rich dataset of meteorological parameters.

```{r, warning = FALSE}
# ---- Library Loading ----
library(dplyr)
library(caret)
library(pROC)
library(e1071)
library(readr)
library(ggplot2)
library(DataExplorer)
library(visdat)
library(corrplot)
library(leaps)
library(tidyverse)
library(MASS)  
library(vip)
library(ResourceSelection)
library(car)
library(ROCR)
library(DescTools)
```

```{r, , warning = FALSE}
# ---- Data Loading ----
train_data <- read.table("/Users/telcimerve/Desktop/Dauphine/Generalized LM/Modèles linéaires généralisés - R. RYDER-20240611/Projet/meteo.train.csv", header = TRUE, sep = ",")
test_data <- read.table("/Users/telcimerve/Desktop/Dauphine/Generalized LM/Modèles linéaires généralisés - R. RYDER-20240611/Projet/meteo.test.csv", header = TRUE, sep = ",")
```

```{r, warning = FALSE}
# ---- Data Exploration ----
head(train_data)
summary(train_data)
print(paste("Missing values in training data:", sum(is.na(train_data))))
print(paste("Missing values in test data:", sum(is.na(test_data))))
sapply(train_data, function(x) length(unique(x)))
```

## 2. Data Description

### Source

The dataset comprises an extensive collection of meteorological measurements recorded daily between 2010 and 2018. These parameters include:

- Temperature: Ambient air temperature at multiple times throughout each day.
- Humidity: Atmospheric moisture levels, crucial for predicting weather patterns.
- Cloud Cover: Observations at various altitudes, providing insights into the vertical structure of the atmosphere.
- Wind Characteristics: Both speed and direction, measured at different heights, which are vital for understanding and forecasting weather fronts and systems.
- Precipitation: Detailed records of rainfall and other precipitation events, fundamental for hydrological forecasting.

### Data Completeness and Initial Transformations:
Remarkably, this dataset contains no missing values, demonstrating its reliability and comprehensive nature. Given my focus on non-time-series predictive modeling, I will implement several preprocessing steps to optimize the dataset for my analytical goals:

- Date Transformation: I will convert exact dates into a day-of-the-year format (ranging from 1 to 365). This adjustment allows me to capture seasonal effects more effectively while discarding unnecessary temporal granularity.
- Feature Reduction: I will systematically remove columns that do not contribute to predictive accuracy or that duplicate information, streamlining the dataset for more efficient analysis.

```{r, warning = FALSE}
# ---- Data Transformation ----
train_data$day_of_year <- as.integer(format(as.Date(with(train_data, paste(Year, Month, Day, sep="-"))), "%j"))
test_data$day_of_year <- as.integer(format(as.Date(with(test_data, paste(Year, Month, Day, sep="-"))), "%j"))
train_data[, c("Year", "Month", "Day", "Hour", "Minute")] <- NULL
test_data[, c("Year", "Month", "Day", "Hour", "Minute")] <- NULL
```

### Evaluating Potential Predictors
Given the numerous potential predictors in my dataset, it is crucial to meticulously examine their distributions and characteristics. This analysis will inform necessary transformations or eliminations to refine the models. By identifying skewed distributions or outliers, I can apply appropriate statistical transformations to normalize data, enhancing model reliability and performance. Similarly, recognizing and removing redundant or irrelevant predictors will prevent model overfitting and improve computational efficiency. This step is fundamental in evolving my models to achieve optimal predictive accuracy.

```{r, warning = FALSE}
# ---- Data Visualization ----
plot_histogram(train_data)
plot_boxplot(train_data, by = "pluie.demain", ncol = 3)
nzv <- nearZeroVar(train_data, saveMetrics = TRUE)
print(nzv)
```

### Column Diagnostics and Recommendations

#### Temperature (Daily Mean 2 m Above Ground)
- **Description:** Displays a normal distribution.

#### Relative Humidity (Daily Mean 2 m Above Ground)
- **Description:** Generally normal but slightly skewed.

#### Mean Sea Level Pressure (Daily Mean)
- **Description:** Slightly skewed, indicating potential for improvement.

#### Total Precipitation (Daily Sum at Surface)
- **Description:** Highly skewed with many zero entries.

#### Wind Speed (Daily Max 10 m Above Ground)
- **Description:** Exhibits right skewness.

#### Wind Gust (Daily Max at Surface)
- **Description:** Likely skewed.

#### Correlation Analysis
- **Approach:** To effectively manage the extensive data, I will utilize a correlation heatmap. This tool will help visualize relationships between variables. I will categorize variables and assess correlations within and across these groups to refine the model's structure and variable selection.

This structured diagnostic approach ensures each variable's inclusion or transformation in the GLM is not only justified but also optimizes the model's predictive accuracy and interpretability.


```{r, warning = FALSE}
# ---- Feature Engineering ----
temperature_vars <- c("Temperature.daily.mean..2.m.above.gnd.", "Temperature.daily.max..2.m.above.gnd.", "Temperature.daily.min..2.m.above.gnd.")
humidity_vars <- c("Relative.Humidity.daily.mean..2.m.above.gnd.", "Relative.Humidity.daily.max..2.m.above.gnd.", "Relative.Humidity.daily.min..2.m.above.gnd.")
pressure_vars <- c("Mean.Sea.Level.Pressure.daily.mean..MSL.", "Mean.Sea.Level.Pressure.daily.max..MSL.", "Mean.Sea.Level.Pressure.daily.min..MSL.")
wind_vars <- c(
  "Wind.Speed.daily.mean..10.m.above.gnd.", "Wind.Direction.daily.mean..10.m.above.gnd.", 
  "Wind.Speed.daily.mean..80.m.above.gnd.", "Wind.Direction.daily.mean..80.m.above.gnd.", 
  "Wind.Speed.daily.mean..900.mb.", "Wind.Direction.daily.mean..900.mb.", "Wind.Gust.daily.mean..sfc.",
  "Wind.Speed.daily.max..10.m.above.gnd.", "Wind.Speed.daily.min..10.m.above.gnd.", 
  "Wind.Speed.daily.max..80.m.above.gnd.", "Wind.Speed.daily.min..80.m.above.gnd.", 
  "Wind.Speed.daily.max..900.mb.", "Wind.Speed.daily.min..900.mb.", "Wind.Gust.daily.max..sfc.", 
  "Wind.Gust.daily.min..sfc."
)
cloud_cover_vars <- c(
  "Total.Cloud.Cover.daily.max..sfc.", "Total.Cloud.Cover.daily.mean..sfc.", "Total.Cloud.Cover.daily.min..sfc.",
  "High.Cloud.Cover.daily.max..high.cld.lay.", "High.Cloud.Cover.daily.mean..high.cld.lay.", "High.Cloud.Cover.daily.min..high.cld.lay.",
  "Medium.Cloud.Cover.daily.max..mid.cld.lay.", "Medium.Cloud.Cover.daily.mean..mid.cld.lay.", "Medium.Cloud.Cover.daily.min..mid.cld.lay.",
  "Low.Cloud.Cover.daily.max..low.cld.lay.", "Low.Cloud.Cover.daily.mean..low.cld.lay.", "Low.Cloud.Cover.daily.min..low.cld.lay."
)
```

```{r, warning = FALSE}
# ---- Correlation Analysis ----
cor_analysis <- function(data, var_category) {
  cor_data <- data[, c(var_category, "pluie.demain", "Total.Precipitation.daily.sum..sfc.")]
  cor_matrix <- cor(cor_data, use = "complete.obs")
  return(cor_matrix)
}
temp_cor <- cor_analysis(train_data, temperature_vars)
humidity_cor <- cor_analysis(train_data, humidity_vars)
pressure_cor <- cor_analysis(train_data, pressure_vars)
wind_cor <- cor_analysis(train_data, wind_vars)
cloud_cor <- cor_analysis(train_data, cloud_cover_vars)

plot_corr <- function(cor_matrix, title) {
  corrplot(cor_matrix, method = "circle", type = "upper", order = "hclust",
           tl.col = "black", tl.srt = 45, title = title, addCoef.col = "black", 
           cl.cex = 0.8, tl.cex = 0.8)
}

par(mfrow = c(1, 1))
plot_corr(temp_cor, "Temperature Correlations")
plot_corr(humidity_cor, "Humidity Correlations")
plot_corr(pressure_cor, "Pressure Correlations")
plot_corr(wind_cor, "Wind Correlations")
plot_corr(cloud_cor, "Cloud Cover Correlations")
```

### Variable Correlation Analysis and Recommendations

#### 1. Temperature Correlations
- **Correlations with Rain Tomorrow:** All temperature measurements show low correlations with rain tomorrow, ranging from 0.09 to 0.15.
- **Inter-correlations:** There is high redundancy among temperature variables, suggesting overlapping information.
- To reduce complexity, I consider using only one temperature measurement.

#### 2. Humidity Correlations
- **Correlations with Rain Tomorrow:** Humidity variables exhibit very low correlations with the occurrence of rain (approx. 0.03).
- **Inter-correlations:** There are high correlations between daily mean and maximum humidity levels.
- Same action

#### 3. Pressure Correlations
- **Correlations with Rain Tomorrow:** Moderate negative correlations with rain tomorrow, between -0.35 and -0.39.
- **Inter-correlations:** Pressure variables are highly correlated among themselves, indicating redundancy.
- Same action

#### 4. Wind Correlations
- **Correlations with Rain Tomorrow:** Wind speed variables show moderate correlations with the occurrence of rain, ranging from 0.19 to 0.23.
- **Inter-correlations:** There is extremely high correlation among different wind speed measures, suggesting redundant information.
- Choose representative variables

#### 5. Cloud Cover Correlations
- **Correlations with Rain Tomorrow:** Moderate to high correlations observed, particularly for total cloud cover and high cloud cover, which range from 0.32 to 0.41.
- **Inter-correlations:** Strong correlations exist between different measures of cloud cover.
- Same action


```{r, warning = FALSE}
# ---- Data Transformations ----
# Manually specifying transformations based on histogram and correlation analysis
# Applying log transformations to skewed variables with many zeros
train_data$Total.Precipitation.log <- log1p(train_data$Total.Precipitation.daily.sum..sfc.)
train_data$Snowfall.Amount.log <- log1p(train_data$Snowfall.amount.raw.daily.sum..sfc.)
test_data$Total.Precipitation.log <- log1p(test_data$Total.Precipitation.daily.sum..sfc.)
test_data$Snowfall.Amount.log <- log1p(test_data$Snowfall.amount.raw.daily.sum..sfc.)

# Square root transformation for variables with right-skewed distributions
train_data$Wind.Speed.10m.sqrt <- sqrt(train_data$Wind.Speed.daily.mean..10.m.above.gnd.)
train_data$Wind.Gust.Max.sqrt <- sqrt(train_data$Wind.Gust.daily.max..sfc.)
test_data$Wind.Speed.10m.sqrt <- sqrt(test_data$Wind.Speed.daily.mean..10.m.above.gnd.)
test_data$Wind.Gust.Max.sqrt <- sqrt(test_data$Wind.Gust.daily.max..sfc.)

# Standardizing normally distributed but varying scale variables
train_data$Temperature.mean.scaled <- scale(train_data$Temperature.daily.mean..2.m.above.gnd.)
train_data$Humidity.mean.scaled <- scale(train_data$Relative.Humidity.daily.mean..2.m.above.gnd.)
train_data$Pressure.MSL.scaled <- scale(train_data$Mean.Sea.Level.Pressure.daily.mean..MSL.)
test_data$Temperature.mean.scaled <- scale(test_data$Temperature.daily.mean..2.m.above.gnd.)
test_data$Humidity.mean.scaled <- scale(test_data$Relative.Humidity.daily.mean..2.m.above.gnd.)
test_data$Pressure.MSL.scaled <- scale(test_data$Mean.Sea.Level.Pressure.daily.mean..MSL.)
```

### Data Split
-   **Training Data**: 80% of the data used to build and tune the models.
-   **Test Data**: 20% of the data used to validate the model’s performance, ensuring it generalizes well to unseen data.

```{r, warning = FALSE}
# ---- Data Prep ----
train_data$pluie.demain <- ifelse(train_data$pluie.demain == TRUE, 1, 0)
training_rows <- createDataPartition(train_data$pluie.demain, p = 0.8, list = TRUE)$Resample1
data_train <- train_data[training_rows, ]
data_val <- train_data[-training_rows, ]
data_val$pluie.demain <- factor(data_val$pluie.demain, levels = c("0", "1"))
```

### Initial Model Construction

#### Overview
The initial model, also known as the "full model," incorporates all available meteorological variables. This comprehensive approach allows us to establish a baseline understanding of the potential predictive power of each variable without prior filtering or reduction. 

#### Model Specification
- **Model Type:** Generalized Linear Model (GLM)
- **Response Variable:** Rain Tomorrow (`pluie.demain`), a binary outcome indicating whether it will rain.
- **Predictors:** All collected meteorological variables, including temperature, humidity, cloud cover, wind characteristics, and precipitation metrics.
- **Link Function:** Logistic, suitable for binary outcomes, modeling the probability of rain.

#### Rationale
Building an initial model with all variables is crucial for several reasons:
- **Baseline Performance:** It serves as a benchmark against which the performance of more parsimonious models can be measured.
- **Variable Importance:** Allows for the initial assessment of the importance and influence of each variable on the prediction of rain.
- **Identification of Redundancy:** Helps identify multicollinearity and redundancy among variables, guiding subsequent model refinement.


```{r initial-model, echo=TRUE}
# Building the initial model
initial_model <- glm(pluie.demain ~ ., data = data_train, family = binomial())
summary(initial_model)
vip(initial_model)
par(mfrow = c(2, 2))
plot(initial_model)
```

### Development of the Second Model

#### Rationale and Methodology

Following the initial model, the second model was developed by selectively removing variables based on their statistical significance and contribution to the model's predictive accuracy. This approach aims to streamline the model, enhancing its interpretability and efficiency.


```{r, warning = FALSE}
# ---- Second Model Fitting ----
second_model <- glm(pluie.demain ~ Mean.Sea.Level.Pressure.daily.min..MSL. +
                      Mean.Sea.Level.Pressure.daily.mean..MSL.+
                      Mean.Sea.Level.Pressure.daily.max..MSL.+
                      Wind.Direction.daily.mean..900.mb.+
                      Snowfall.amount.raw.daily.sum..sfc.+
                      Wind.Speed.daily.min..10.m.above.gnd. +
                      Wind.Speed.daily.max..10.m.above.gnd. +
                      Temperature.daily.min..2.m.above.gnd. +
                      Medium.Cloud.Cover.daily.max..mid.cld.lay. + 
                      Medium.Cloud.Cover.daily.mean..mid.cld.lay., 
                    data = data_train, family = binomial())
summary(second_model)
vip(second_model)
par(mfrow = c(2, 2))
plot(second_model)
```

### Development of the Manual Model

#### Rationale

The manual model is developed through a targeted selection process of variables, guided by insights gained from correlation maps. This strategic approach involves choosing predictors that demonstrate significant individual correlations with the target variable and minimal multicollinearity with each other. This method ensures that the model retains only the most relevant and independent variables, enhancing both its interpretability and predictive accuracy.

#### Overview

This model leverages manual curation to refine the predictor set, focusing on those variables that are not only influential but also provide unique informational value. This hands-on selection process helps in maintaining model simplicity while potentially improving its performance by reducing redundancy and enhancing the clarity of the relationships being modeled.


```{r, warning = FALSE}
# ---- Manual adjusted model----
manual_model <- glm(pluie.demain ~ Mean.Sea.Level.Pressure.daily.min..MSL. +
                      Mean.Sea.Level.Pressure.daily.mean..MSL.+
                      Mean.Sea.Level.Pressure.daily.max..MSL.+
                      Wind.Direction.daily.mean..900.mb.+
                      Snowfall.amount.raw.daily.sum..sfc.+
                      Wind.Speed.daily.min..10.m.above.gnd. +
                      Wind.Speed.daily.max..10.m.above.gnd. +
                      Temperature.daily.min..2.m.above.gnd. +
                      Medium.Cloud.Cover.daily.max..mid.cld.lay. + 
                      Medium.Cloud.Cover.daily.mean..mid.cld.lay.+
                      day_of_year + 
                      Shortwave.Radiation.daily.sum..sfc. + 
                      Sunshine.Duration.daily.sum..sfc. , 
                    data = data_train, family = binomial())
summary(manual_model)
vip(manual_model)
par(mfrow = c(2, 2))
plot(manual_model)
```

### Development of the Advanced Model

#### Rationale

This advanced model incorporates transformations that address issues identified from histogram analyses, such as skewness in variable distributions. By applying logarithmic or normalization transformations to specific variables, the model aims to improve the linearity of the relationships and the homoscedasticity of residuals, which are crucial for the effective application of generalized linear models.

#### Overview

Transformations were chosen based on the distribution characteristics of each variable, with the goal of stabilizing variance and normalizing data. This process enhances model accuracy and the robustness of inference by ensuring that the underlying assumptions of the statistical models are better met. The use of transformed variables helps in capturing more complex nonlinear relationships that might be missed in untransformed data, potentially leading to more accurate and reliable predictions.


```{r, warning = FALSE}
# ---- Advanced Model fitting---- 
# Fit logistic regression model using the specified transformations
model_formula <- pluie.demain ~ Total.Precipitation.log +
  Wind.Speed.10m.sqrt + Wind.Gust.Max.sqrt +
  Temperature.mean.scaled + Humidity.mean.scaled + Pressure.MSL.scaled
advanced_model <- glm(model_formula, family = binomial, data = data_train)

summary(advanced_model)
vip(advanced_model)
par(mfrow = c(2, 2))
plot(advanced_model)
```

### Application of Model Selection Techniques

#### Rationale

To further refine the predictive accuracy and efficiency of the initial, second, and advanced models, various model selection techniques were employed. These techniques, including forward selection, backward elimination, and stepwise regression, help in identifying the most significant predictors while controlling for overfitting and enhancing model simplicity.

#### Overview

The application of these selection techniques allows for a dynamic evaluation of each model's performance as predictors are added or removed based on statistical criteria such as the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC). This iterative process helps in fine-tuning the models by:
- **Reducing Complexity:** Minimizing the number of predictors while retaining those that provide substantial information.
- **Improving Predictive Power:** Enhancing the model's ability to predict new data accurately by focusing on the most impactful variables.
- **Ensuring Model Robustness:** Avoiding overfitting by including only variables that significantly improve model performance.

These techniques are applied sequentially to each model, starting with the initial comprehensive setup and progressing through more focused models, to systematically optimize the variable selection for each scenario.


```{r, warning = FALSE}
# ---- Selection techniques (Forward, Backward, Stepwise) ----
forward_model <- glm(pluie.demain ~ 1, data = train_data, family = binomial())
forward_model <- step(forward_model, direction = "forward", scope = list(lower = forward_model, upper = initial_model))
summary(forward_model)
vip(forward_model)
par(mfrow = c(2, 2))
plot(forward_model)

backward_model <- step(initial_model, direction = "backward")
summary(backward_model)
vip(backward_model)
par(mfrow = c(2, 2))
plot(backward_model)

stepwise_model <- step(initial_model, direction = "both", trace = TRUE)
summary(stepwise_model)
vip(stepwise_model)
par(mfrow = c(2, 2))
plot(stepwise_model)

stepwise_model_second <- step(second_model, direction = "both", trace = TRUE)
summary(stepwise_model_second)
vip(stepwise_model_second)
par(mfrow = c(2, 2))
plot(stepwise_model_second)

stepwise_model_advanced <- step(advanced_model, direction = "both", trace = TRUE)
summary(stepwise_model_advanced)
vip(stepwise_model_advanced)
par(mfrow = c(2, 2))
plot(stepwise_model_advanced)

forward_model_advanced <- step(advanced_model, direction = "forward", scope = list(lower = advanced_model, upper = initial_model))
summary(forward_model_advanced)
vip(forward_model_advanced)
par(mfrow = c(2, 2))
plot(forward_model_advanced)
```

```{r, warning = FALSE}
# --- Model comparisons ---
model_metrics <- sapply(list(initial_model, second_model, manual_model, advanced_model, forward_model, backward_model, stepwise_model, stepwise_model_second, stepwise_model_advanced, forward_model_advanced),
                        function(model) {
                          c(AIC = AIC(model),
                            BIC = BIC(model),
                            Num_Parameters = length(coef(model)))
                        })
model_metrics <- t(model_metrics)
colnames(model_metrics) <- c("AIC", "BIC", "Num_Parameters")
rownames(model_metrics) <- c("Initial", "Second", "Manual", "Advanced", "Forward", "Backward", "Stepwise", "Stepwise-second", "Stepwise-advanced", "Forward-advanced")
print(model_metrics)

# Store models in a list
models_list <- list(
  Initial = initial_model,
  Second = second_model,
  Manual = manual_model,
  Advanced = advanced_model,
  Forward = forward_model,
  Backward = backward_model,
  Stepwise = stepwise_model,
  Stepwise_Second = stepwise_model_second,
  Stepwise_Advanced = stepwise_model_advanced,
  Forward_advanced = forward_model_advanced
)

# Define the evaluation function if not already defined
evaluate_model <- function(model, data) {
  predictions_prob <- predict(model, data, type = "response")
  predictions_class <- ifelse(predictions_prob > 0.5, "1", "0")
  predictions_class <- factor(predictions_class, levels = c("0", "1"))
  
  cm <- confusionMatrix(predictions_class, data$pluie.demain)
  list(
    Accuracy = cm$overall['Accuracy'],
    Precision = cm$byClass['Pos Pred Value'],
    Recall = cm$byClass['Sensitivity'],
    F1 = (2 * cm$byClass['Precision'] * cm$byClass['Sensitivity']) / (cm$byClass['Precision'] + cm$byClass['Sensitivity']),
    AUC = roc(response = as.numeric(data$pluie.demain), predictor = as.numeric(predictions_prob))$auc
  )
}

# Apply the evaluation to all models
evaluation_results <- lapply(models_list, evaluate_model, data = data_val)

# Print results
print(evaluation_results)
```

### Model Evaluation Summary

Initial evaluations highlight the Forward Advanced and Stepwise models as particularly promising. To finalize my decision, I will further analyze the ROC curves and AUC statistics for these models, ensuring that the selected model optimally balances accuracy and generalizability.


```{r, warning = FALSE}
# ---- Model Comparison - continue ----
# Function to plot ROC curve
plot_roc_curve <- function(model, data, title) {
  predictions <- predict(model, data, type = "response")
  roc_obj <- roc(data$pluie.demain, predictions)
  plot(roc_obj, main = paste("ROC Curve for", title))
  abline(a = 0, b = 1, col = "red")
  return(auc(roc_obj))
}

# Apply ROC plotting to each model
roc_results <- sapply(names(models_list), function(name) {
  plot_roc_curve(models_list[[name]], data_val, name)
})

# Print AUC results
print(roc_results)
```

### Selection Justification for the Forward Advanced Model

Given the comprehensive evaluation of performance metrics and model fit, the Forward Advanced model emerges as the optimal choice due to its strong performance and statistical robustness:

#### Performance Metrics:
- **Accuracy:** 0.7458 - Indicates robustness in making correct predictions.
- **Precision:** 0.76 - Reflects high reliability in positive predictions.
- **Recall:** 0.6786 - Represents a good balance, capturing a significant proportion of positive cases.
- **F1 Score:** 0.7170 - Balances precision and recall, critical for models where both are important.
- **AUC:** 0.7882 - Shows good discriminative ability across various thresholds.

#### Statistical Model Fit:
- **AIC:** 1023.604 - Suggests an effective balance between fit and complexity.
- **BIC:** 1120.606 - Indicates simplicity relative to the number of predictors, enhancing generalization.
- **Num_Parameters:** 20 - Suggests a complexity that captures necessary data nuances without overfitting.

#### Overall Justification:
- **Balanced Performance:** The model performs well across key metrics, supporting its effectiveness under different operational conditions.
- **Efficient Model Complexity:** Low AIC and BIC values indicate no overfitting despite the relatively high number of parameters, suggesting that the complexity is justified and crucial for capturing underlying data patterns.
- **Practical Implications:** High precision is particularly valuable in scenarios where the cost of false positives is critical, ensuring that decisions based on model predictions are reliable.
- **Robustness and Generalization:** With competitive statistical indicators and a reasonable parameter count, the model is likely to generalize well, making it suitable for real-world applications where performance consistency is key.

#### Conclusion:
The Forward Advanced model's high precision and accuracy, combined with robust statistical indicators, make it a superior choice for applications requiring dependable and actionable insights. Its well-balanced features ensure that it can manage both the complexity of the data and the need for generalization without sacrificing prediction accuracy.


```{r, warning = FALSE}
# ---- Model visualisation  ----
coef_df <- broom::tidy(forward_model_advanced) %>%
  dplyr::filter(term != "(Intercept)") %>%
  dplyr::mutate(estimate_abs = abs(estimate)) %>%
  dplyr::arrange(desc(estimate_abs))

ggplot(coef_df, aes(x = reorder(term, estimate_abs), y = estimate, fill = estimate > 0)) +
  geom_col() +
  coord_flip() +
  labs(title = "Feature Importance in Forward Model",
       x = "Features",
       y = "Coefficient Value") +
  theme_minimal()

par(mfrow = c(1, 1))

residuals_df <- data.frame(residuals = residuals(forward_model_advanced), fitted = fitted.values(forward_model_advanced))
ggplot(residuals_df, aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.5) +
  geom_smooth(se = FALSE, color = "blue") +
  labs(title = "Residuals vs Fitted Values",
       x = "Fitted Values",
       y = "Residuals") +
  theme_minimal()
```

### Application of the Chosen Model to Test Data

#### Overview

Once the Forward Advanced model was selected based on its superior performance and robustness, the next critical step involved applying this model to the test data. This phase is essential for evaluating how well the model generalizes to new, unseen data, providing a realistic assessment of its predictive capabilities.

#### Process

The application process involves:
- Using the chosen model to predict outcomes on the test dataset.
- Comparing these predictions against the actual outcomes to assess accuracy and other performance metrics.

#### Implications

This step not only validates the effectiveness of the model in a controlled test environment but also highlights potential areas for further refinement. It is crucial for ensuring that the model's performance is consistent and reliable when deployed in real-world scenarios.


```{r, warning = FALSE}
# ---- Prediction  ----
# Predict the probabilities on the test dataset
predictions_test_prob <- predict(forward_model_advanced, test_data, type = "response")

# Convert probabilities to binary predictions
predictions_test_class <- ifelse(predictions_test_prob > 0.5, TRUE, FALSE)

# Add the binary predictions to the test data
test_data$pluie.demain <- predictions_test_class

# View the first few rows of the updated test data
head(test_data)

# Save the updated test data to a new CSV file
write.table(test_data, "/Users/telcimerve/Desktop/Dauphine/Generalized LM/Modèles linéaires généralisés - R. RYDER-20240611/Projet/meteo.test_with_predictions.csv", sep = ",", row.names = FALSE, col.names = TRUE)
```

```{r, warning = FALSE}
# ---- Prediction visualisation  ----
# Histogram of predicted probabilities
ggplot(data.frame(predictions_test_prob), aes(x = predictions_test_prob)) +
  geom_histogram(binwidth = 0.05, fill = "blue", color = "black") +
  labs(title = "Histogram of Predicted Probabilities", x = "Predicted Probability", y = "Frequency") +
  theme_minimal()

# Bar plot of predicted classes
ggplot(data.frame(predictions_test_class), aes(x = factor(predictions_test_class))) +
  geom_bar(fill = "green", color = "black") +
  labs(title = "Bar Plot of Predicted Classes", x = "Predicted Class", y = "Count") +
  theme_minimal()

```

### Conclusion

Applying the Forward Advanced model to the test data serves as the final validation of its predictive power. This process confirms the model's utility in practical applications and solidifies its role as a dependable tool for meteorological forecasting. Further adjustments and optimizations may be pursued based on the insights gained during this testing phase.
